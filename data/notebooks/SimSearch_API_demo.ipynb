{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Attribute Similarity Search for Interactive Data Exploration with the SimSearch REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to an instance of the SimSearch service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Various custom helper functions\n",
    "from functions import results_pairwise, flatten, changeDataType, map_points, weighted_heatmap, filterNaN, filter_dict_median, frequency, barchart, plot_wordcloud, generate_color\n",
    "\n",
    "# Use 5 decimal digits for floating numerical values\n",
    "pd.options.display.float_format = '{:,.5f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the web service\n",
    "# E.g., assuming that the SimSearch service has been deployed locally at port 8090:\n",
    "serviceURL = 'http://localhost:8090/simsearch/api/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*Mount request*__: Define data sources available for similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  __IMPORTANT!__ This step needs to be performed __once__ for each data source. \n",
    "##### Once data is successfully ingested, it can be queried as long as the SimSearch service is up-and-running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a mount request to the SimSearch API that will index the data sources specified in the parameters\n",
    "mount = serviceURL + 'index'\n",
    "\n",
    "# JSON specification for the data sources and the similarity operations supported for their attributes\n",
    "# In this example, note that the CSV dataset is available at a REMOTE HTTP server; however, data may be also available at the server's file system\n",
    "# The spatial operation makes use of two attributes (longitude, latitude) available in the original dataset, but it is mentioned with an alias ('position'):\n",
    "params = {'sources':[{'name':'remotePath1','type':'csv','url':'http://download.smartdatalake.eu/datasets/gdelt/'}], 'search':[{'operation':'spatial_knn','source':'remotePath1','dataset':'sample.csv','header':'true','separator':',','key_column':'article_id','search_column':['longitude','latitude'],'alias_column':'position'}, {'operation':'categorical_topk','source':'remotePath1','dataset':'sample.csv','separator':',','token_delimiter':';','header':'true','key_column':'article_id','search_column':'persons'}, {'operation':'temporal_topk','source':'remotePath1','dataset':'sample.csv','separator':',','header':'true','key_column':'article_id','search_column':'timestamp'}]}\n",
    "\n",
    "# IMPORTANT! No API key is required for such requests\n",
    "# A new API key will be generated once this request completes successfully\n",
    "headers = {'Content-Type' : 'application/json'}\n",
    "\n",
    "# Post this request with these parameters\n",
    "resMount = requests.post(mount, json=params, headers=headers)\n",
    "\n",
    "# Provide the resulting message (with the API key to be used in subsequent requests)\n",
    "print(resMount.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __IMPORTANT!__ Remember your API key for subsequent requests to this SimSearch instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a dictionary from the response ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictMount = json.loads(resMount.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ... and extract the API key necessary for connecting to the SimSearch instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep your API key obtained from the mount request for further use with any other requests against this instance\n",
    "API_KEY = dictMount.get('apiKey')\n",
    "API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*Append request*__: Include extra attributes to this SimSearch instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specify the dataset, the attributes and the respective similarity operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify an append request to the SimSearch API that will also index the data sources specified in the parameters\n",
    "mount = serviceURL + 'append'\n",
    "\n",
    "# JSON specification for the data source(s) and the similarity operations supported for their attributes\n",
    "# In this example, note that the CSV dataset must be available at the local file system (in the server)\n",
    "params = {'sources':[{'name':'localPath1','type':'csv','directory':'/data/gdelt/}], 'search':[{'operation':'numerical_topk','source':'localPath1','dataset':'sample.csv','separator':',','header':'true','key_column':'article_id','search_column':'positive_sentiment'}, {'operation':'numerical_topk','source':'localPath1','dataset':'sample.csv','separator':',','header':'true','key_column':'article_id','search_column':'negative_sentiment'}]}\n",
    "\n",
    "# IMPORTANT! API key is required for such requests\n",
    "headers = { 'api_key' : API_KEY, 'Content-Type' : 'application/json'}\n",
    "\n",
    "# Post this request with these parameters\n",
    "resAppend = requests.post(mount, json=params, headers=headers)\n",
    "\n",
    "# Provide the resulting message (with the API key to be used in subsequent requests)\n",
    "print(resAppend.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*Catalog request*__: List all queryable attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a catalog request to the SimSearch API\n",
    "catalog = serviceURL + 'catalog'\n",
    "\n",
    "# JSON specification may be empty in order to list all available attributes ...\n",
    "params = {}\n",
    "\n",
    "# ... or specify a particular type of similarity operation\n",
    "#params= {'operation': 'numerical_topk'}\n",
    "\n",
    "# API key is required for such requests\n",
    "headers = { 'api_key' : API_KEY, 'Content-Type' : 'application/json'}\n",
    "\n",
    "# Post this request with these parameters to the SimSearch service; response is given in a JSON array\n",
    "response = requests.post(catalog, json=params, headers=headers)\n",
    "#print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the queryable attributes, their data types, and their supported similarity operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attrs = pd.DataFrame(response.json())\n",
    "attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*Search request*__: submit a top-*k* similarity search query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired number of top-k results to return\n",
    "k = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query values per attribute involved in this search request:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each query value should conform with the data type of the respective attribute\n",
    "valKeywords = ['donald trump', 'joe biden', 'vladimir putin']\n",
    "valTimestamp = '2019-07-14 12:45:00'\n",
    "valPosSentiment = '2.5'\n",
    "valPosition = 'POINT(2.35 48.85)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weight specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that multiple combinations of weights are specified per attribute; In this example, two lists of top-k results will be returned\n",
    "weightKeywords = ['1.0','0.8']\n",
    "weightTimestamp = ['1.0','0.9']\n",
    "weightPosSentiment = ['1.0','0.3']\n",
    "weightPosition = ['1.0','0.6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rank method to apply for similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible values for the ranking algorithm: 'threshold' (default); 'no_random_access; 'partial_random_access'; 'pivot_based'.\n",
    "rankMethod = 'threshold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compose & submit this search request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a search request to the SimSearch API\n",
    "search = serviceURL + 'search'\n",
    "\n",
    "# Specify all query parameters\n",
    "# Can also specify extra attributes (not involved in similarity conditions) to be included in the list of query results\n",
    "params = {'algorithm':rankMethod, 'output': {'extra_columns':['negative_sentiment','name']}, 'k':k, 'queries':[{'column':'persons','value':valKeywords ,'weights':weightKeywords}, {'column':'positive_sentiment','value':valPosSentiment ,'weights':weightPosSentiment}, {'column':'timestamp','value':valTimestamp,'weights':weightTimestamp}, {'column':'position','value':valPosition,'weights':weightPosition}]}\n",
    "\n",
    "# Valid API key is required for such requests\n",
    "headers = { 'api_key' : API_KEY, 'Content-Type' : 'application/json'}\n",
    "\n",
    "# Post this request with these parameters to the SimSearch service; response is given in a JSON array\n",
    "resSearch = requests.post(search, json=params, headers=headers)\n",
    "#print(resSearch.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report final ranked results: An array of top-k results is returned for each specified combination of weights.\n",
    "For each combination, a similarity matrix is also returned, measuring the similarity between all pairs of the top-k results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(resSearch.json())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a given combination of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = df['weights']\n",
    "# E.g., the ***2nd*** combination of weights for the attributes\n",
    "print(weights.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-*k* results for each combination of weights\n",
    "Also flatten attribute values and scores contained in the nested JSON array returned as response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [None] * len(weights)\n",
    "\n",
    "# Results for each combination  of weights\n",
    "# This flattening returns geodataframes, i.e., one column holds geometries (point locations)\n",
    "for index, item in enumerate(weights):\n",
    "    results[index] = flatten(df['rankedResults'].iloc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing of results for a given batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the table as HTML with clickable URLs\n",
    "display(HTML(results[1].to_html(render_links=True,escape=False)))\n",
    "\n",
    "# Results for the 1st combination of weights\n",
    "#results[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intra-Correlation: Similarity of the results for a given combination of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create as many plots as the weight combinations\n",
    "fig, ax = plt.subplots(1,len(weights),figsize=(10,10))\n",
    "\n",
    "simMatrix = [None] * len(weights)\n",
    "# Create a pivot table for the similarity matrix of each weight combination and plot it\n",
    "for index, item in enumerate(weights):\n",
    "    plt.subplot(1, len(weights), index+1)\n",
    "    sim = pd.DataFrame(df['similarityMatrix'].iloc[index])\n",
    "    simMatrix[index] = sim.pivot(index='left', columns='right', values='score')\n",
    "    plt.imshow(simMatrix[index], interpolation='none')\n",
    "    plt.title('W' + str(index+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-Correlation: Statistics regarding pairwise correlation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, create lists of rankings for two batches of results (i.e., from two combinations of weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E.g., A is the second and B is the fourth batch of SimSearch results\n",
    "A, B = results_pairwise(results[0], results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pearson's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(A.values[0], B.values[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spearman's rho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(A.values[0], B.values[0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kendall's tau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.kendalltau(A, B)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map plots from each batch based on the spatial locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listMapPoints = []    # clustered points with a BBOX showing the overall spatial extent\n",
    "listHeatmaps = []     # heatmaps illutrating the spatial density\n",
    "\n",
    "# Create all map plots from each batch of results (weight combinations)\n",
    "for index, item in enumerate(weights):\n",
    "    listMapPoints.append(map_points(results[index], show_bbox=True))\n",
    "    listHeatmaps.append(weighted_heatmap(results[index], radius=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot clustered points for each batch of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = ''\n",
    "numPlots = sum(m is not None for m in listMapPoints)\n",
    "percent = (100.0/numPlots) - 0.5\n",
    "\n",
    "# Construct an HTML for displaying maps side-by-side\n",
    "for m in listMapPoints:\n",
    "    if m is not None:\n",
    "        contents += '<iframe srcdoc=\"{}\" style=\"float:left; width: {}px; height: {}px; display:inline-block; width: {}%; margin: 0 auto; border: 2px solid black\"></iframe>'.format(m.get_root().render().replace('\"', '&quot;'),400,400,percent)\n",
    "\n",
    "display(HTML(contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot heatmaps for each batch of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = ''\n",
    "numPlots = sum(m is not None for m in listHeatmaps)\n",
    "percent = (100.0/numPlots) - 0.5\n",
    "\n",
    "# Construct an HTML for displaying heatmaps side-by-side\n",
    "for m in listHeatmaps:\n",
    "    if m is not None:\n",
    "        contents += '<iframe srcdoc=\"{}\" style=\"float:left; width: {}px; height: {}px; display:inline-block; width: {}%; margin: 0 auto; border: 2px solid black\"></iframe>'.format(m.get_root().render().replace('\"', '&quot;'),400,400,percent)\n",
    "\n",
    "display(HTML(contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display maps of clustered points side-by-side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **IMPORTANT!** First, specify the attribute that contains _keywords_, required in creating workclouds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrKeywords = 'persons_value'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-10 keywords per batch of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, item in enumerate(weights):\n",
    "    # Use only those keywords above the median frequency for each batch\n",
    "    kf = filter_dict_median(frequency(results[index],attrKeywords))\n",
    "    # Create barchart\n",
    "    barchart(kf, plot_width=4, plot_height=3, orientation='Horizontal', plot_title='keywords for W'+str(index+1), x_axis_label='Frequency', top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word cloud per batch of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(results[0], attrKeywords)\n",
    "\n",
    "plot_wordcloud(results[1], attrKeywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations for numerical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms to display distribution of values for numerical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **IMPORTANT!** First, specify the attribute that contains _numerical_ values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the attribute containing the numerical values of interest in the response\n",
    "attrNumeric = 'positive_sentiment_value'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNumerical = [None] * len(weights)\n",
    "dfBins = [None] * len(weights)\n",
    "numBins = 20  # fixed number of bins\n",
    "\n",
    "# Create as many plots as the weight combinations\n",
    "fig, ax = plt.subplots(1,len(weights))\n",
    "\n",
    "# Figure size per histogram\n",
    "fig.set_figheight(3) # optional setting the height of the image\n",
    "fig.set_figwidth(16) # optional setting the width of the image\n",
    "\n",
    "# Create histogram from numerical data values for each combination  of weights\n",
    "for index, item in enumerate(weights):\n",
    "    dfNumerical[index] =  results[index][attrNumeric] #pd.to_numeric(results[index][attrNumeric], errors='coerce')\n",
    "    bins = np.linspace(math.ceil(min(dfNumerical[index])), math.floor(max(dfNumerical[index])), numBins) \n",
    "    label = ' '.join(str(weights[index]))\n",
    "    ax[index].hist(dfNumerical[index], bins=dfBins[index], alpha = 0.8) #, color = generate_color(weights[index]))\n",
    "    ax[index].set(title='W'+str(index+1), ylabel='Frequency', xlabel=attrNumeric)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots to show the mean value and the distribution of values per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "box_plot_data=[filterNaN(results[0][attrNumeric]),filterNaN(results[1][attrNumeric])]\n",
    "ax.boxplot(box_plot_data)\n",
    "\n",
    "# Custom ticks\n",
    "plt.xticks([1, 2], ['W1', 'W2'])\n",
    "\n",
    "plt.gca().set(title='Distribution per Weight combination', ylabel=attrNumeric)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot distribution on date/time attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **IMPORTANT!** First, specify the date/time attribute of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrTemporal = 'timestamp_value'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency histograms on MONTH (extracted from timestamp values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTemporal = [None] * len(weights)\n",
    "\n",
    "# Create as many plots as the weight combinations\n",
    "fig, ax = plt.subplots(1,len(weights))\n",
    "\n",
    "# Figure size per histogram\n",
    "fig.set_figheight(3) # optional setting the height of the image\n",
    "fig.set_figwidth(16) # optional setting the width of the image\n",
    "\n",
    "# Plot aggregate values per MONTH for each combination  of weights\n",
    "for index, item in enumerate(weights):\n",
    "    dfTemporal[index] =  results[index][attrTemporal]\n",
    "    dfTemporal[index].groupby(dfTemporal[index].dt.month).count().plot.bar(ax=ax[index])\n",
    "    ax[index].set(title='W'+str(index+1), ylabel='Frequency', xlabel='Month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geo (Python 3.8)",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
