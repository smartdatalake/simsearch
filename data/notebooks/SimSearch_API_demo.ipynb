{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Attribute Similarity Search for Interactive Data Exploration with the SimSearch REST API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection to an instance of the SimSearch service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Various custom helper functions\n",
    "from functions import results_pairwise, flatten, changeDataType, map_points, filterNaN, filter_dict_median, frequency, barchart, plot_wordcloud, generate_color\n",
    "\n",
    "# Use 5 decimal digits for floating numerical values\n",
    "pd.options.display.float_format = '{:,.5f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the web service\n",
    "# E.g., assuming that the SimSearch service has been deployed locally at port 8090:\n",
    "serviceURL = 'http://localhost:8090/simsearch/api/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*Mount request*__: Define data sources available for similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  __IMPORTANT!__ This step needs to be performed __once__ for each data source. \n",
    "##### Once data is successfully ingested, it can be queried as long as the SimSearch service is up-and-running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a mount request to the SimSearch API that will index the data sources specified in the parameters\n",
    "mount = serviceURL + 'index'\n",
    "\n",
    "# JSON specification for the data sources and the similarity operations supported for their attributes\n",
    "# In this example, note that the CSV dataset is available at a remote HTTP server\n",
    "params = {'sources':[{'name':'remotePath1','type':'csv','url':'http://download.smartdatalake.eu/datasets/gdelt/'}], 'search':[{'operation':'spatial_knn','source':'remotePath1','dataset':'sample.csv','header':'true','separator':',','key_column':'article_id','search_column':['longitude','latitude']}, {'operation':'categorical_topk','source':'remotePath1','dataset':'sample.csv','separator':',','token_delimiter':';','header':'true','key_column':'article_id','search_column':'persons'}, {'operation':'numerical_topk','source':'remotePath1','dataset':'sample.csv','separator':',','header':'true','key_column':'article_id','search_column':'timestamp'}]}\n",
    "\n",
    "# IMPORTANT! No API key is required for such requests\n",
    "# A new API key will be generated once this request completes successfully\n",
    "headers = {'Content-Type' : 'application/json'}\n",
    "\n",
    "# Post this request with these parameters\n",
    "response = requests.post(mount, json=params, headers=headers)\n",
    "\n",
    "# Provide the resulting message (with the API key to be used in subsequent requests)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __IMPORTANT!__ Remember your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy below your API key obtained from the above request for further use with any other requests against this instance\n",
    "API_KEY = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*Catalog request*__: List the queryable attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a catalog request to the SimSearch API\n",
    "catalog = serviceURL + 'catalog'\n",
    "\n",
    "# JSON specification may be empty in order to list all available attributes ...\n",
    "params = {}\n",
    "\n",
    "# ... or specify a particular type of similarity operation\n",
    "#params= {'operation': 'numerical_topk'}\n",
    "\n",
    "# API key is required for such requests\n",
    "headers = { 'api_key' : API_KEY, 'Content-Type' : 'application/json'}\n",
    "\n",
    "# Post this request with these parameters to the SimSearch service; response is given in a JSON array\n",
    "response = requests.post(catalog, json=params, headers=headers)\n",
    "#print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the queryable attributes and their supported similarity operations. Note that the spatial operation makes use of two attributes (lon, lat) available in the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attrs = pd.DataFrame(response.json())\n",
    "attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __*Search request*__: submit a top-*k* similarity search query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a search request to the SimSearch API\n",
    "search = serviceURL + 'search'\n",
    "\n",
    "# Count of top-k results to be returned\n",
    "k = 30\n",
    "\n",
    "# Rank aggregation method to be used; Possible values for the ranking algorithm: 'threshold' (default); 'no_random_access'\"'; '\"'partial_random_access'\"'.\n",
    "rankMethod = 'threshold'\n",
    "\n",
    "# Query values for similarity search \n",
    "valKeywords = ['donald trump', 'joe biden', 'vladimir putin']\n",
    "valLocation = 'POINT(-74.94 42.15)'\n",
    "valTimestamp = 20191104084500\n",
    "\n",
    "# Specify all query parameters\n",
    "# Note that multiple combinations of weights are specified per attribute -> In this example, two lists of top-k results will be computed\n",
    "params = {'algorithm':rankMethod, 'k':k, 'queries':[{'column':'persons','value':valKeywords ,'weights':['1.0','0.8']}, {'column':'timestamp','value':valTimestamp,'weights':['1.0','0.4']}, {'column':['longitude','latitude'],'value':valLocation,'weights':['1.0','0.7']}]}\n",
    "\n",
    "# Valid API key is required for such requests\n",
    "headers = { 'api_key' : API_KEY, 'Content-Type' : 'application/json'}\n",
    "\n",
    "# Post this request with these parameters to the SimSearch service; response is given in a JSON array\n",
    "response = requests.post(search, json=params, headers=headers)\n",
    "#print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report final ranked results: An array of top-k results is returned for each specified combination of weights.\n",
    "For each combination, a similarity matrix is also returned, measuring the similarity between all pairs of the top-k results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(response.json())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a given combination of weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = df['weights']\n",
    "# E.g., the ***2nd*** combination of weights for the attributes\n",
    "print(weights.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-*k* results for each combination of weights\n",
    "Also flatten attribute values and scores contained in the nested JSON array returned as response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [None] * len(weights)\n",
    "\n",
    "# Results for each combination  of weights\n",
    "# This flattening returns geodataframes, i.e., one column holds geometries (point locations)\n",
    "for index, item in enumerate(weights):\n",
    "    results[index] = flatten(df['rankedResults'].iloc[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listing of results for a given batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the table as HTML with clickable URLs\n",
    "display(HTML(results[0].to_html(render_links=True,escape=False)))\n",
    "\n",
    "# Results for the 1st combination of weights\n",
    "#results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intra-Correlation: Similarity of the results for a given combination of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create as many plots as the weight combinations\n",
    "fig, ax = plt.subplots(1,len(weights),figsize=(10,10))\n",
    "\n",
    "simMatrix = [None] * len(weights)\n",
    "# Create a pivot table for the similarity matrix of each weight combination and plot it\n",
    "for index, item in enumerate(weights):\n",
    "    plt.subplot(1, len(weights), index+1)\n",
    "    sim = pd.DataFrame(df['similarityMatrix'].iloc[index])\n",
    "    simMatrix[index] = sim.pivot(index='left', columns='right', values='score')\n",
    "    plt.imshow(simMatrix[index], interpolation='none')\n",
    "    plt.title('W ' + str(weights[index]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-Correlation: Statistics regarding pairwise correlation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, create lists of rankings for two batches of results (i.e., from two combinations of weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "# E.g., A is the second and B is the fourth batch of SimSearch results\n",
    "A, B = results_pairwise(results[0], results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pearson's:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(A.values[0], B.values[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spearman's rho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(A.values[0], B.values[0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kendall's tau:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.kendalltau(A, B)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map plots from each batch based on the spatial locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = map_points(results[0], show_bbox=True)\n",
    "m1 = map_points(results[1], show_bbox=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Display maps of clustered points side-by-side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlmap1 = HTML('<iframe srcdoc=\"{}\" style=\"float:left; width: {}px; height: {}px; display:inline-block; width: 48.5%; margin: 0 auto; border: 2px solid black\"></iframe>'\n",
    "           '<iframe srcdoc=\"{}\" style=\"float:right; width: {}px; height: {}px; display:inline-block; width: 48.5%; margin: 0 auto; border: 2px solid black\"></iframe>'\n",
    "           .format(m0.get_root().render().replace('\"', '&quot;'),400,400,\n",
    "                   m1.get_root().render().replace('\"', '&quot;'),400,400\n",
    "                  ))\n",
    "\n",
    "display(htmlmap1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top-10 keywords per batch of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the attribute containing keywords in the response\n",
    "col_keywords = 'persons_value'\n",
    "\n",
    "for index, item in enumerate(weights):\n",
    "    # Use only those keywords above the median frequency for each batch\n",
    "    kf = filter_dict_median(frequency(results[index],col_keywords))\n",
    "    # Create barchart\n",
    "    barchart(kf, plot_width=4, plot_height=3, orientation='Horizontal', plot_title='keywords for W '+' '.join(str(weights[index])), x_axis_label='Frequency', top_k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word cloud per batch of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud(results[0], col_keywords)\n",
    "\n",
    "plot_wordcloud(results[1], col_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations for numerical attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution of numerical values for a given attribute using histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the attribute containing the numerical values of interest in the response\n",
    "col_Numerical = 'timestamp_value'\n",
    "\n",
    "dfNumerical = [None] * len(weights)\n",
    "dfBins = [None] * len(weights)\n",
    "numBins = 20  # fixed number of bins\n",
    "\n",
    "# Create as many plots as the weight combinations\n",
    "fig, ax = plt.subplots(1,len(weights))\n",
    "\n",
    "# Figure size per histogram\n",
    "fig.set_figheight(3) # optional setting the height of the image\n",
    "fig.set_figwidth(16) # optional setting the width of the image\n",
    "\n",
    "# Create histogram from numerical data values for each combination  of weights\n",
    "for index, item in enumerate(weights):\n",
    "    dfNumerical[index] =  pd.to_numeric(results[index][col_Numerical], errors='coerce')\n",
    "    bins = np.linspace(math.ceil(min(dfNumerical[index])), math.floor(max(dfNumerical[index])), numBins) \n",
    "    label = ' '.join(str(weights[index]))\n",
    "    ax[index].hist(dfNumerical[index], bins=dfBins[index], alpha = 0.8, color = generate_color(weights[index]))\n",
    "    ax[index].set(title='W '+label, ylabel='Frequency')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots to show the mean value and the distribution of values per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "box_plot_data=[filterNaN(results[0][col_Numerical]),filterNaN(results[1][col_Numerical])]\n",
    "ax.boxplot(box_plot_data)\n",
    "\n",
    "# Custom ticks\n",
    "plt.xticks([1, 2], ['W1', 'W2'])\n",
    "\n",
    "plt.gca().set(title='Distribution per Weight combination', ylabel=col_Numerical)\n",
    "ax.set_yscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
